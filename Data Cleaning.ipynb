{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c4b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6f7c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9ac6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/24 20:45:21 WARN Utils: Your hostname, sid-HP-240-G3-Notebook-PC resolves to a loopback address: 127.0.1.1; using 192.168.1.100 instead (on interface wlp9s0f0)\n",
      "21/07/24 20:45:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/sid/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/24 20:45:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/07/24 20:45:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkSession.builder.appName('Cheatsheet').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f881f",
   "metadata": {},
   "source": [
    "### Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffd94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reading CSV in pandas\n",
    "df = pd.read_csv('data/T1.csv')\n",
    "\n",
    "# Reading CSV in PySpark\n",
    "spark_df = sc.read.option(\"header\",True) \\\n",
    "                  .csv(\"data/T1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6669cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50530 entries, 0 to 50529\n",
      "Data columns (total 5 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Date/Time                      50530 non-null  object \n",
      " 1   LV ActivePower (kW)            50530 non-null  float64\n",
      " 2   Wind Speed (m/s)               50530 non-null  float64\n",
      " 3   Theoretical_Power_Curve (KWh)  50530 non-null  float64\n",
      " 4   Wind Direction (째)             50530 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2327cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date/Time: string (nullable = true)\n",
      " |-- LV ActivePower (kW): string (nullable = true)\n",
      " |-- Wind Speed (m/s): string (nullable = true)\n",
      " |-- Theoretical_Power_Curve (KWh): string (nullable = true)\n",
      " |-- Wind Direction (째): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd1c5f",
   "metadata": {},
   "source": [
    "### Nerdy Tip\n",
    "\n",
    "* **pandas** uses auto infer mechanism by default while in **PySpark** the `inferSchema` is set to `False` by default.\n",
    "\n",
    "\n",
    "* While reading the CSV in pandas use `parse_dates` parameter for converting the column type to `datetime`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b7e84",
   "metadata": {},
   "source": [
    "## Infer dtypes while reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93657f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50530 entries, 0 to 50529\n",
      "Data columns (total 5 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   Date/Time                      50530 non-null  datetime64[ns]\n",
      " 1   LV ActivePower (kW)            50530 non-null  float64       \n",
      " 2   Wind Speed (m/s)               50530 non-null  float64       \n",
      " 3   Theoretical_Power_Curve (KWh)  50530 non-null  float64       \n",
      " 4   Wind Direction (째)             50530 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/T1.csv', parse_dates=['Date/Time'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b5fcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = sc.read.options(header=True, inferSchema=True) \\\n",
    "                  .csv(\"data/T1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b4a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date/Time: string (nullable = true)\n",
      " |-- LV ActivePower (kW): double (nullable = true)\n",
      " |-- Wind Speed (m/s): double (nullable = true)\n",
      " |-- Theoretical_Power_Curve (KWh): double (nullable = true)\n",
      " |-- Wind Direction (째): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
