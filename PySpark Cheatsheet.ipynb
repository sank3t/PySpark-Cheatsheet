{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31948de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9d6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba845589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/24 19:08:40 WARN Utils: Your hostname, sid-HP-240-G3-Notebook-PC resolves to a loopback address: 127.0.1.1; using 192.168.43.10 instead (on interface wlp9s0f0)\n",
      "21/07/24 19:08:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/sid/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/07/24 19:08:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9109b",
   "metadata": {},
   "source": [
    "## Reading CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed038fad",
   "metadata": {},
   "source": [
    "### pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070f8063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>LV ActivePower (kW)</th>\n",
       "      <th>Wind Speed (m/s)</th>\n",
       "      <th>Theoretical_Power_Curve (KWh)</th>\n",
       "      <th>Wind Direction (°)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 01 2018 00:00</td>\n",
       "      <td>380.047791</td>\n",
       "      <td>5.311336</td>\n",
       "      <td>416.328908</td>\n",
       "      <td>259.994904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01 01 2018 00:10</td>\n",
       "      <td>453.769196</td>\n",
       "      <td>5.672167</td>\n",
       "      <td>519.917511</td>\n",
       "      <td>268.641113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01 01 2018 00:20</td>\n",
       "      <td>306.376587</td>\n",
       "      <td>5.216037</td>\n",
       "      <td>390.900016</td>\n",
       "      <td>272.564789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01 01 2018 00:30</td>\n",
       "      <td>419.645905</td>\n",
       "      <td>5.659674</td>\n",
       "      <td>516.127569</td>\n",
       "      <td>271.258087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01 01 2018 00:40</td>\n",
       "      <td>380.650696</td>\n",
       "      <td>5.577941</td>\n",
       "      <td>491.702972</td>\n",
       "      <td>265.674286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date/Time  LV ActivePower (kW)  Wind Speed (m/s)  \\\n",
       "0  01 01 2018 00:00           380.047791          5.311336   \n",
       "1  01 01 2018 00:10           453.769196          5.672167   \n",
       "2  01 01 2018 00:20           306.376587          5.216037   \n",
       "3  01 01 2018 00:30           419.645905          5.659674   \n",
       "4  01 01 2018 00:40           380.650696          5.577941   \n",
       "\n",
       "   Theoretical_Power_Curve (KWh)  Wind Direction (°)  \n",
       "0                     416.328908          259.994904  \n",
       "1                     519.917511          268.641113  \n",
       "2                     390.900016          272.564789  \n",
       "3                     516.127569          271.258087  \n",
       "4                     491.702972          265.674286  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/T1.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe57082",
   "metadata": {},
   "source": [
    "### PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e05dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = sc.read.option(\"header\",True) \\\n",
    "     .csv(\"data/T1.csv\")\n",
    "\n",
    "spark_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
